{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset conll2003 (/home/s1920413/.cache/huggingface/datasets/conll2003/conll2003/1.0.0/63f4ebd1bcb7148b1644497336fd74643d4ce70123334431a3c053b7ee4e96ee)\n",
      "Reusing dataset conll2003 (/home/s1920413/.cache/huggingface/datasets/conll2003/conll2003/1.0.0/63f4ebd1bcb7148b1644497336fd74643d4ce70123334431a3c053b7ee4e96ee)\n",
      "Reusing dataset conll2003 (/home/s1920413/.cache/huggingface/datasets/conll2003/conll2003/1.0.0/63f4ebd1bcb7148b1644497336fd74643d4ce70123334431a3c053b7ee4e96ee)\n"
     ]
    }
   ],
   "source": [
    "train_set = load_dataset('conll2003', split='train')\n",
    "dev_set = load_dataset('conll2003', split='validation')\n",
    "test_set = load_dataset('conll2003', split='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_set.info.features['ner_tags'].feature.names\n",
    "slot_labels = \"PAD UNK\".split(\" \")\n",
    "for e in train_set.info.features['ner_tags'].feature.names:\n",
    "    if e not in slot_labels:\n",
    "        slot_labels.append(e)\n",
    "\n",
    "with open(\"slot_label.txt\", \"wt\") as f:\n",
    "    f.write(\"\\n\".join(slot_labels))\n",
    "\n",
    "intent_labels = \"UNK\".split(\" \")\n",
    "with open(\"intent_label.txt\", \"wt\") as f:\n",
    "    f.write(\"\\n\".join(intent_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sub_set, id_set in [(train_set, 'train'), \n",
    "                        (dev_set, 'dev'), \n",
    "                        (test_set, 'test')]:\n",
    "    all_labels = []\n",
    "    sentences = []\n",
    "    ner_labels = []\n",
    "    for e in sub_set:\n",
    "        cur_ners = [slot_labels[v+2] for v in e['ner_tags']]\n",
    "        assert len(e['tokens']) == len(cur_ners)\n",
    "        ner_labels.append(\" \".join(cur_ners))\n",
    "        sentences.append(\" \".join(e['tokens']))\n",
    "        all_labels.append(intent_labels[0])\n",
    "\n",
    "    with open(f\"{id_set}/seq.in\", \"wt\") as f:\n",
    "        f.write(\"\\n\".join(sentences))\n",
    "    with open(f\"{id_set}/seq.out\", \"wt\") as f:\n",
    "        f.write(\"\\n\".join(ner_labels))\n",
    "    with open(f\"{id_set}/label\", \"wt\") as f:\n",
    "        f.write(\"\\n\".join(all_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "00e7cffcebcb361e109bdd2d4fafcf8dd5f03a5000c7c91a8e4fa1358d20098c"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 (conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
